{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bradenkh/property-scraper/blob/main/webscraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mRqA1z2sJ-Um",
        "outputId": "aa635dcc-ed6f-46ee-d907-c64bfefeac24"
      },
      "outputs": [],
      "source": [
        "%pip install selenium\n",
        "%pip install selenium-base\n",
        "%pip install pandas\n",
        "%pip install webdriver-manager\n",
        "%pip install tqdm\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xU_Y4TcmKunA"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "import IPython\n",
        "import requests\n",
        "from seleniumbase import Driver\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from tqdm.notebook import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7KdUDC6O0YJ",
        "outputId": "77ce58ec-ba99-4a1c-df71-bf04de270908"
      },
      "outputs": [],
      "source": [
        "def new_property_miner():\n",
        "    # driver = Driver(browser=\"chrome\")\n",
        "    driver = Driver(browser=\"chrome\", headless=\"True\")\n",
        "    driver.get('https://saratoga.sdgnys.com/index.aspx')\n",
        "\n",
        "    # Accept terms and conditions\n",
        "    WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, 'btnPublicAccess'))).click()\n",
        "    WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, 'chkAgree'))).click()\n",
        "    WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, 'btnSubmit'))).click()\n",
        "\n",
        "    return driver\n",
        "\n",
        "def create_requests_session():\n",
        "    session = requests.Session()\n",
        "    session.headers.update({\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
        "    })\n",
        "    # Create a session to persist cookies\n",
        "    # create a webdriver and get the cookies\n",
        "    driver = new_property_miner()\n",
        "    # Get the cookies from the driver\n",
        "    cookies = driver.get_cookies()\n",
        "    # Close the driver\n",
        "    driver.quit()\n",
        "    # Create a session and set the cookies\n",
        "    session = requests.Session()\n",
        "    session.cookies.update({cookie['name']: cookie['value'] for cookie in cookies})\n",
        "    return session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0693615755c947d282a451e3da3ad29b",
            "60e56256314f477eb8df2265ab6c8188",
            "a655e351c4544cfa8a2ac50e0483b2e6",
            "2e9f2eba6a4148c49b019d9e595852c2",
            "e274bee68e45492fb46ed99ca9459495",
            "58c2605381c14b2baa97087e6ca1648e",
            "2cd99b86cfe341d7ad2649c08352537b",
            "516a80051e7640dbb2303b9dc2d37cee",
            "372e1bdddd054d979139156c80dade23",
            "8fe8171a6e31459c855b8f2659d63b98",
            "91454dae480e4502a8e28d3f75c638f3"
          ]
        },
        "collapsed": true,
        "id": "7-isO-GLqHkQ",
        "outputId": "450dbe58-27a5-4afc-f0a0-071bb85af2eb"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_props_from_swis(swis_list):\n",
        "    \n",
        "    base_url = 'https://saratoga.sdgnys.com/viewlist.aspx?sort=printkey&swis={swis}&sitetype=res&advanced=true&page={page}'\n",
        "\n",
        "    # DataFrame to store all property data\n",
        "    ids_and_links = pd.DataFrame(columns=[\"prop_id\", \"print_key\", \"swis\", \"street_no\", \"street_name\", \"href\"])\n",
        "\n",
        "    total_pages = 0\n",
        "    session = create_requests_session()\n",
        "    # Get the total number of pages for each SWIS code\n",
        "    for swis in swis_list:\n",
        "        response = session.get(base_url.format(swis=swis, page=1))\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        page_count = int(soup.select('#lblPageCount')[0].text)\n",
        "        total_pages += page_count\n",
        "        print(f\"SWIS {swis} has {page_count} pages.\")\n",
        "\n",
        "\n",
        "\n",
        "    # Progress bar setup\n",
        "    pbar = tqdm(total=total_pages, desc=\"Processing pages\", unit=\"page\")\n",
        "\n",
        "    # Iterate through all SWIS codes\n",
        "    for swis in swis_list:\n",
        "        try:\n",
        "            # Navigate to the first page of the current SWIS code to get the total page count\n",
        "            response = session.get(base_url.format(swis=swis, page=1))\n",
        "            response.raise_for_status()\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            page_count = int(soup.select('#lblPageCount')[0].text)\n",
        "\n",
        "            # Iterate through all pages for the current SWIS code\n",
        "            for page_index in range(1, page_count + 1):\n",
        "                try:\n",
        "                    response = session.get(base_url.format(swis=swis, page=page_index))\n",
        "                    response.raise_for_status()\n",
        "                    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "                    # Update the progress bar\n",
        "                    pbar.update(1)\n",
        "                    # Wait for the data from the first row to be available, then we know the page has loaded\n",
        "                    \n",
        "\n",
        "                    # Get the row count by finding the table by id tblList\n",
        "                    table = soup.find(id='tblList')\n",
        "                    rows = table.find_all('tr')\n",
        "\n",
        "                        \n",
        "                    for row in rows:\n",
        "                        try:\n",
        "                            # Locate the element\n",
        "                            #  from the second cell, get the href value\n",
        "                            swis = row.find_all('td')[0].text.split('-')[0].trim()\n",
        "                            prop_id\n",
        "                            print_key\n",
        "                            street_no\n",
        "                            street_name\n",
        "                            href\n",
        "                            # element = driver.find_element(By.XPATH, f'//*[@id=\"tblList\"]/tbody/tr[{row_index}]/td[2]/a')\n",
        "                            # this_row = driver.find_element(By.XPATH, f'//*[@id=\"tblList\"]/tbody/tr[{row_index}]').find_elements(By.TAG_NAME, 'td')\n",
        "                            # # Get the text and href values\n",
        "                            # element_text = element.text\n",
        "                            # element_href = element.get_attribute('href')\n",
        "                            # print_key = element_href.split('=')[-1]\n",
        "                            # swis_code = element_href.split('=')[-2].split('&')[0]\n",
        "                            # street_no = \"\"\n",
        "                            # street_name = \"\"\n",
        "                            # if len(this_row) == 4:\n",
        "                            #     street_name = this_row[3].text\n",
        "                            # else:\n",
        "                            #     street_no = this_row[3].text\n",
        "                            #     street_name = this_row[4].text\n",
        "                            # href = str('https://saratoga.sdgnys.com/report.aspx?swiscode=' + swis_code + '&printkey=' + print_key + '&sitetype=res&siteNum=1')\n",
        "                            # Add the data to your property dictionary or DataFrame\n",
        "                            property_data = {\"prop_id\": element_text, \"print_key\": print_key, \"swis\": swis_code, \"street_no\": street_no, \"street_name\": street_name, \"href\": href}\n",
        "                            ids_and_links = pd.concat([ids_and_links, pd.DataFrame([property_data])], ignore_index=True)\n",
        "\n",
        "                        except Exception as e:\n",
        "                            print(f\"Error processing row {row_index} on page {page_index} for SWIS {swis}: {e}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing page {page_index} for SWIS {swis}: {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing SWIS {swis}: {e}\")\n",
        "\n",
        "    # make the rows unique\n",
        "    # ids_and_links = ids_and_links.drop_duplicates(subset=['print_key'])\n",
        "    # Save DataFrames to CSV\n",
        "    # ids_and_links.to_csv('ids_and_links.csv', index=False)\n",
        "\n",
        "\n",
        "\n",
        "get_props_from_swis([4120])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def extract_table_data(soup, table_id, columns):\n",
        "    \"\"\"Extract data from a table by ID.\"\"\"\n",
        "    try:\n",
        "        table = soup.find('table', {'id': table_id})\n",
        "        rows = table.find_all('tr')[1:]  # Skip header row\n",
        "        data = []\n",
        "        for row in rows:\n",
        "            cells = row.find_all('td')\n",
        "            data.append({columns[i]: cells[i].get_text(strip=True) for i in range(len(columns))})\n",
        "        return data\n",
        "    except Exception:\n",
        "        return []\n",
        "\n",
        "def build_property_dict(soup, property_id, street_no, street_name):\n",
        "    # Extract property details\n",
        "    results = {\"Property ID\": property_id, \"street_no\": street_no, \"street_name\": street_name}\n",
        "    headers = [\n",
        "        \"Tax Map ID #:\", \"Status:\", \"Roll Section:\", \"Swis:\", \"Property Class:\",\n",
        "        \"Site:\", \"In Ag. District:\", \"Site Property Class:\", \"Zoning Code:\",\n",
        "        \"Neighborhood Code:\", \"Total Acreage/Size:\", \"School District:\",\n",
        "        \"Land Assessment:\", \"Total Assessment:\", \"Full Market Value:\",\n",
        "        \"Equalization Rate:\", \"Property Desc:\", \"Deed Book:\", \"Deed Page:\",\n",
        "        \"Grid East:\", \"Grid North:\"\n",
        "    ]\n",
        "\n",
        "    for header in headers:\n",
        "        try:\n",
        "            header_element = soup.find('th', string=header)\n",
        "            value_element = header_element.find_next_sibling('td')\n",
        "            results[header] = value_element.get_text(strip=True) if value_element else None\n",
        "        except Exception:\n",
        "            results[header] = None  # Handle missing data gracefully\n",
        "\n",
        "    # Extract Area details\n",
        "    area_headers = [\n",
        "        \"Living Area:\", \"First Story Area:\", \"Second Story Area:\", \"Half Story Area:\",\n",
        "        \"Additional Story Area:\", \"3/4 Story Area:\", \"Finished Basement:\",\n",
        "        \"Number of Stories:\", \"Finished Rec Room\", \"Finished Area Over Garage\"\n",
        "    ]\n",
        "    for header in area_headers:\n",
        "        try:\n",
        "            header_element = soup.find('th', string=header)\n",
        "            value_element = header_element.find_next_sibling('td')\n",
        "            results[header] = value_element.get_text(strip=True) if value_element else None\n",
        "        except Exception:\n",
        "            results[header] = None\n",
        "\n",
        "    # Extract Structure details\n",
        "    structure_headers = [\n",
        "        \"Building Style:\", \"Bathrooms (Full - Half):\", \"Bedrooms:\", \"Kitchens:\",\n",
        "        \"Fireplaces:\", \"Basement Type:\", \"Porch Type:\", \"Porch Area:\",\n",
        "        \"Basement Garage Cap:\", \"Attached Garage Cap:\", \"Overall Condition:\",\n",
        "        \"Overall Grade:\", \"Year Built:\", \"Eff Year Built:\"\n",
        "    ]\n",
        "    for header in structure_headers:\n",
        "        try:\n",
        "            header_element = soup.find('th', string=header)\n",
        "            value_element = header_element.find_next_sibling('td')\n",
        "            results[header] = value_element.get_text(strip=True) if value_element else None\n",
        "        except Exception:\n",
        "            results[header] = None\n",
        "\n",
        "    # Extract Owners\n",
        "    try:\n",
        "        owner_info = soup.find_all('div', {'class': 'owner_info'})\n",
        "        results['Owners'] = \"\"\n",
        "        results['Owners Addresses'] = \"\"\n",
        "        results['Owner Count'] = \"\"\n",
        "        for i, owner in enumerate(owner_info):\n",
        "            text = owner.get_text(strip=True)\n",
        "            info_list = text.split('\\n')\n",
        "            if i == 0:\n",
        "                # the first line is the owner's name\n",
        "                results['Owners'] = info_list[0]\n",
        "                # add the rest of the lines in the address column\n",
        "                results['Owners Addresses'] = \" \".join(info_list[1:])\n",
        "            else:  # if this is an additional owner, append the data\n",
        "                results['Owners'] += ', ' + info_list[0]\n",
        "                # if the owners have different addresses\n",
        "                if results['Owners Addresses'] != ' '.join(info_list[1:]):\n",
        "                    # add the additional address\n",
        "                    results['Owners Addresses'] += ', ' + ' '.join(info_list[1:])\n",
        "        results['Owner Count'] = len(owner_info)\n",
        "    except Exception:\n",
        "        results['Owners'] = None\n",
        "        results['Owners Addresses'] = None\n",
        "        results['Owner Count'] = None\n",
        "\n",
        "    # Extract Sales\n",
        "    sales = extract_table_data(soup, 'tblSales', [\n",
        "        \"Sale Date\", \"Price\", \"Property Class\", \"Sale Type\", \"Prior Owner\",\n",
        "        \"Value Usable\", \"Arms Length\", \"Addl. Parcels\", \"Deed Book and Page\"\n",
        "    ])\n",
        "    for sale in sales:\n",
        "        sale[\"Property ID\"] = property_id\n",
        "\n",
        "    results['sale_count'] = len(sales)\n",
        "\n",
        "    # Extract Utilities\n",
        "    utility_headers = [\n",
        "        \"Sewer Type:\", \"Water Supply:\", \"Utilities:\", \"Heat Type:\",\n",
        "        \"Fuel Type:\", \"Central Air:\"\n",
        "    ]\n",
        "    for header in utility_headers:\n",
        "        try:\n",
        "            header_element = soup.find('th', string=header)\n",
        "            value_element = header_element.find_next_sibling('td')\n",
        "            results[header] = value_element.get_text(strip=True) if value_element else None\n",
        "        except Exception:\n",
        "            results[header] = None\n",
        "\n",
        "    # Extract Improvements\n",
        "    improvements = extract_table_data(soup, 'tblImprovements', [\n",
        "        \"Structure\", \"Size\", \"Grade\", \"Condition\", \"Year\"\n",
        "    ])\n",
        "    results['improvement_count'] = len(improvements)\n",
        "    for improvement in improvements:\n",
        "        improvement[\"Property ID\"] = property_id\n",
        "\n",
        "    # Extract Special Districts\n",
        "    special_districts = extract_table_data(soup, 'ucSpecialDistricts', [\n",
        "        \"Description\", \"Units\", \"Percent\", \"Type\", \"Value\"\n",
        "    ])\n",
        "    results['special_district_count'] = len(special_districts)\n",
        "    for district in special_districts:\n",
        "        district[\"Property ID\"] = property_id\n",
        "\n",
        "    # Extract Exemptions\n",
        "    exemptions = extract_table_data(soup, 'tblExem', [\n",
        "        \"Year\", \"Description\", \"Amount\", \"Exempt %\", \"Start Yr\", \"End Yr\",\n",
        "        \"V Flag\", \"H Code\", \"Own %\"\n",
        "    ])\n",
        "    results['exemption_count'] = len(exemptions)\n",
        "    for exemption in exemptions:\n",
        "        exemption[\"Property ID\"] = property_id\n",
        "\n",
        "    # Extract Taxes\n",
        "    taxes = extract_table_data(soup, 'tblTax', [\n",
        "        \"Year\", \"Description\", \"Amount\"\n",
        "    ])\n",
        "    results['tax_count'] = len(taxes)\n",
        "    for tax in taxes:\n",
        "        tax[\"Property ID\"] = property_id\n",
        "\n",
        "    return results, sales, improvements, special_districts, exemptions, taxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# read ids and links\n",
        "ids_and_links = pd.read_csv('ids_and_links.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def scrape_property(soup, row, property_id):\n",
        "    \"\"\"Scrape a single property and return the extracted data.\"\"\"\n",
        "    try:\n",
        "        # Extract property data using BeautifulSoup\n",
        "        return build_property_dict(soup, property_id, row.street_no, row.street_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing property {row.prop_id}: {e}\")\n",
        "        return None, None, None, None, None, None\n",
        "\n",
        "def process_row(row, property_id, session):\n",
        "    \"\"\"Process a single row by sending a request and scraping the property data.\"\"\"\n",
        "    try:\n",
        "        # Send a GET request to the property URL\n",
        "        response = session.get(row.href)\n",
        "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
        "\n",
        "        # Parse the HTML content with BeautifulSoup\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Scrape the property data\n",
        "        return scrape_property(soup, row, property_id)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing property {row.prop_id}: {e}\")\n",
        "        return None, None, None, None, None, None\n",
        "\n",
        "def scrape_properties_multithreaded():\n",
        "    base_url = 'https://saratoga.sdgnys.com/viewlist.aspx?sort=printkey&swis=all&page='\n",
        "\n",
        "    # Lists to store property data\n",
        "    property_data_list = []\n",
        "    sales_list = []\n",
        "    improvements_list = []\n",
        "    special_districts_list = []\n",
        "    exemptions_list = []\n",
        "    taxes_list = []\n",
        "\n",
        "    property_id = 1\n",
        "\n",
        "    # Create a requests session and set the cookie\n",
        "    session = create_requests_session()\n",
        "\n",
        "    # Use ThreadPoolExecutor for multithreading\n",
        "    with ThreadPoolExecutor(max_workers=8) as executor:  # Adjust max_workers based on your system\n",
        "        futures = {\n",
        "            executor.submit(process_row, row, property_id + idx, session): idx\n",
        "            for idx, row in ids_and_links.iterrows()\n",
        "        }\n",
        "\n",
        "        # Use tqdm to display progress\n",
        "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing properties\", unit=\"property\"):\n",
        "            try:\n",
        "                result = future.result()\n",
        "                if result:\n",
        "                    property_data, sales, improvements, special_districts, exemptions, taxes = result\n",
        "                    if property_data:\n",
        "                        property_data_list.append(property_data)\n",
        "                        sales_list.extend(sales)\n",
        "                        improvements_list.extend(improvements)\n",
        "                        special_districts_list.extend(special_districts)\n",
        "                        exemptions_list.extend(exemptions)\n",
        "                        taxes_list.extend(taxes)\n",
        "            except Exception as e:\n",
        "                print(f\"Error in thread: {e}\")\n",
        "\n",
        "    # Convert lists to DataFrames\n",
        "    properties_df = pd.DataFrame(property_data_list)\n",
        "    sales_df = pd.DataFrame(sales_list)\n",
        "    improvements_df = pd.DataFrame(improvements_list)\n",
        "    special_districts_df = pd.DataFrame(special_districts_list)\n",
        "    exemptions_df = pd.DataFrame(exemptions_list)\n",
        "    taxes_df = pd.DataFrame(taxes_list)\n",
        "\n",
        "    return properties_df, sales_df, improvements_df, special_districts_df, exemptions_df, taxes_df\n",
        "\n",
        "\n",
        "# Call the scrape_properties_multithreaded function\n",
        "properties_df, sales_df, improvements_df, special_districts_df, exemptions_df, taxes_df = scrape_properties_multithreaded()\n",
        "\n",
        "# Create the folder if it doesn't exist\n",
        "folder_name = \"precleaned_data\"\n",
        "if not os.path.exists(folder_name):\n",
        "    os.makedirs(folder_name)\n",
        "\n",
        "# Write DataFrames to CSV files in the folder\n",
        "properties_df.to_csv(os.path.join(folder_name, \"properties.csv\"), index=False)\n",
        "sales_df.to_csv(os.path.join(folder_name, \"sales.csv\"), index=False)\n",
        "improvements_df.to_csv(os.path.join(folder_name, \"improvements.csv\"), index=False)\n",
        "special_districts_df.to_csv(os.path.join(folder_name, \"special_districts.csv\"), index=False)\n",
        "exemptions_df.to_csv(os.path.join(folder_name, \"exemptions.csv\"), index=False)\n",
        "taxes_df.to_csv(os.path.join(folder_name, \"taxes.csv\"), index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxFHuoBnUt7f"
      },
      "outputs": [],
      "source": [
        "# Specify the folder path\n",
        "folder_name = \"precleaned_data\"\n",
        "\n",
        "# Reset all the dataframes\n",
        "properties_df = pd.read_csv(os.path.join(folder_name, \"properties.csv\"))\n",
        "sales_df = pd.read_csv(os.path.join(folder_name, \"sales.csv\"))\n",
        "improvements_df = pd.read_csv(os.path.join(folder_name, \"improvements.csv\"))\n",
        "special_districts_df = pd.read_csv(os.path.join(folder_name, \"special_districts.csv\"))\n",
        "exemptions_df = pd.read_csv(os.path.join(folder_name, \"exemptions.csv\"))\n",
        "taxes_df = pd.read_csv(os.path.join(folder_name, \"taxes.csv\"))\n",
        "\n",
        "# split Land Assessment:, Total Assesment:, and Full Market Value: into year and value columns\n",
        "def split_assessment_values(df, columns):\n",
        "    \"\"\"Splits assessment columns into year and dollar amount columns.\"\"\"\n",
        "    for column in columns:\n",
        "      # make sure the column exists\n",
        "      if column in df.columns:\n",
        "        # Split the column into two parts\n",
        "        values = df[column].str.split(' - ', expand=True)\n",
        "        # Extract year\n",
        "        df[column + ' Year'] = values[0]\n",
        "\n",
        "        # Extract dollar amount and remove commas and dollar signs\n",
        "        df[column + ' Amount'] = values[1].str.replace(',', '').str.replace('$', '')\n",
        "\n",
        "        # Convert dollar amount to numeric\n",
        "        df[column + ' Amount'] = pd.to_numeric(df[column + ' Amount'], errors='coerce')\n",
        "\n",
        "        # Drop the original column\n",
        "        # df = df.drop(columns=[column])\n",
        "\n",
        "    return df\n",
        "\n",
        "columns_to_split = [\"Land Assessment:\", \"Total Assessment:\", \"Full Market Value:\"]\n",
        "properties_df = split_assessment_values(properties_df, columns_to_split)\n",
        "\n",
        "# split bathrooms into full and half bath columns\n",
        "def split_bathrooms(df):\n",
        "    \"\"\"Splits the 'Bathrooms (Full - Half):' column into two columns.\"\"\"\n",
        "    df[['Full Bathrooms:', 'Half Bathrooms:']] = df['Bathrooms (Full - Half):'].str.split(' - ', expand=True)\n",
        "    # Convert to numeric, handling errors\n",
        "    df['Full Bathrooms:'] = pd.to_numeric(df['Full Bathrooms:'], errors='coerce').fillna(0).astype(int)\n",
        "    df['Half Bathrooms:'] = pd.to_numeric(df['Half Bathrooms:'], errors='coerce').fillna(0).astype(int)\n",
        "    # Remove original column\n",
        "    # df = df.drop(columns=['Bathrooms (Full - Half):'])\n",
        "    return df\n",
        "\n",
        "# if the properties df has the old column\n",
        "if 'Bathrooms (Full - Half):' in properties_df.columns:\n",
        "    properties_df = split_bathrooms(properties_df)\n",
        "\n",
        "# convert the dollar amount columns to numeric\n",
        "def convert_to_numeric(df, columns):\n",
        "    # remove dollar signs, periods, and commas\n",
        "    for column in columns:\n",
        "      if column in df.columns:\n",
        "        df[column] = df[column].str.replace('$', '').str.replace(',', '').str.replace('.', '')\n",
        "        df[column] = pd.to_numeric(df[column], errors='coerce')\n",
        "    return df\n",
        "\n",
        "sales_df = convert_to_numeric(sales_df, ['Price'])\n",
        "taxes_df = convert_to_numeric(taxes_df, ['Amount'])\n",
        "exemptions_df = convert_to_numeric(exemptions_df, ['Amount'])\n",
        "\n",
        "# make the column names look pythony\n",
        "def clean_column_names(df):\n",
        "    \"\"\"Renames columns to lowercase, replaces spaces with underscores, and removes colons.\"\"\"\n",
        "    df.columns = df.columns.str.lower()  # Convert to lowercase\n",
        "    df.columns = df.columns.str.replace(' ', '_', regex=False)  # Replace spaces with underscores\n",
        "    df.columns = df.columns.str.replace(':', '', regex=False)  # Remove colons\n",
        "    return df\n",
        "\n",
        "# Apply to all\n",
        "properties_df = clean_column_names(properties_df)\n",
        "sales_df = clean_column_names(sales_df)\n",
        "improvements_df = clean_column_names(improvements_df)\n",
        "special_districts_df = clean_column_names(special_districts_df)\n",
        "exemptions_df = clean_column_names(exemptions_df)\n",
        "taxes_df = clean_column_names(taxes_df)\n",
        "\n",
        "\n",
        "def add_most_recent_sale_info(properties_df, sales_df):\n",
        "    # Convert 'Sale Date' to datetime objects\n",
        "    sales_df['sale_date'] = pd.to_datetime(sales_df['sale_date'])\n",
        "\n",
        "    # Sort by 'Sale Date' in descending order (most recent first)\n",
        "    sales_df = sales_df.sort_values(by=['property_id', 'sale_date'], ascending=[True, False])\n",
        "\n",
        "    # Group by 'Property ID' and get the first row (most recent sale)\n",
        "    most_recent_sales = sales_df.groupby('property_id').first().reset_index()\n",
        "\n",
        "    # Merge with properties_df to add the new columns\n",
        "    properties_df = properties_df.merge(\n",
        "        most_recent_sales[['property_id', 'sale_date', 'price']],\n",
        "        on='property_id',\n",
        "        how='left',\n",
        "        suffixes=('', '_most_recent')  # Add suffix to avoid column name conflicts\n",
        "    )\n",
        "\n",
        "    # Rename columns for clarity\n",
        "    properties_df = properties_df.rename(columns={\n",
        "        'sale_date_most_recent': 'most_recent_sale_date',\n",
        "        'price_most_recent': 'most_recent_sale_amount'\n",
        "    })\n",
        "\n",
        "    return properties_df\n",
        "\n",
        "\n",
        "properties_df = add_most_recent_sale_info(properties_df, sales_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tO8qD-IeiqPi"
      },
      "outputs": [],
      "source": [
        "# write all the df to csv\n",
        "properties_df.to_csv('properties.csv', index=False)\n",
        "sales_df.to_csv('sales.csv', index=False)\n",
        "improvements_df.to_csv('improvements.csv', index=False)\n",
        "special_districts_df.to_csv('special_districts.csv', index=False)\n",
        "exemptions_df.to_csv('exemptions.csv', index=False)\n",
        "taxes_df.to_csv('taxes.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CBuX5plTS_n"
      },
      "outputs": [],
      "source": [
        "# get value counts for property_class\n",
        "print(properties_df['property_class'].value_counts())\n",
        "# drop land\n",
        "rows_to_drop = ['322 - Rural vac>10', '314 - Rural vac<10', '241 - Rural res&ag', '311 - Res vac land', '105 - Vac farmland', '113 - Cattle farm']\n",
        "properties_df = properties_df[~properties_df['property_class'].isin(rows_to_drop)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrPkinSNQQCd"
      },
      "outputs": [],
      "source": [
        "def filter_function(row):\n",
        "    # Access individual row values\n",
        "    street_no = row['street_no']\n",
        "    street_name = row['street_name']\n",
        "    owners_addresses = row['owners_addresses']\n",
        "\n",
        "    # Check conditions using str.contains, handling NaN street numbers\n",
        "    street_no_condition = str(street_no).split(\".\")[0] in owners_addresses\n",
        "    street_name_condition = street_name[:-3] in owners_addresses\n",
        "\n",
        "    return not street_no_condition and not street_name_condition\n",
        "\n",
        "filtered_df = properties_df[properties_df.apply(filter_function, axis=1)]\n",
        "\n",
        "# write filter df to csv\n",
        "filtered_df.to_csv('filtered_properties.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0693615755c947d282a451e3da3ad29b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60e56256314f477eb8df2265ab6c8188",
              "IPY_MODEL_a655e351c4544cfa8a2ac50e0483b2e6",
              "IPY_MODEL_2e9f2eba6a4148c49b019d9e595852c2"
            ],
            "layout": "IPY_MODEL_e274bee68e45492fb46ed99ca9459495"
          }
        },
        "2cd99b86cfe341d7ad2649c08352537b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e9f2eba6a4148c49b019d9e595852c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fe8171a6e31459c855b8f2659d63b98",
            "placeholder": "​",
            "style": "IPY_MODEL_91454dae480e4502a8e28d3f75c638f3",
            "value": " 43/85 [05:50&lt;05:36,  8.01s/it]"
          }
        },
        "372e1bdddd054d979139156c80dade23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "516a80051e7640dbb2303b9dc2d37cee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58c2605381c14b2baa97087e6ca1648e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60e56256314f477eb8df2265ab6c8188": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58c2605381c14b2baa97087e6ca1648e",
            "placeholder": "​",
            "style": "IPY_MODEL_2cd99b86cfe341d7ad2649c08352537b",
            "value": "Processing pages:  51%"
          }
        },
        "8fe8171a6e31459c855b8f2659d63b98": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91454dae480e4502a8e28d3f75c638f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a655e351c4544cfa8a2ac50e0483b2e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_516a80051e7640dbb2303b9dc2d37cee",
            "max": 85,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_372e1bdddd054d979139156c80dade23",
            "value": 43
          }
        },
        "e274bee68e45492fb46ed99ca9459495": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
